{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일의 환경 변수를 로드\n",
    "load_dotenv()\n",
    "\n",
    "# .env 파일에서 변수 가져오기\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "generation_config = genai.GenerationConfig(\n",
    "\t\tcandidate_count=1,\n",
    "\t\tstop_sequences=['x'],\n",
    "\t\ttemperature=0.7,\n",
    "\t\ttop_p=0.95,\n",
    "\t\t#top_k=64,\n",
    "\t\tmax_output_tokens=8192,\n",
    "\t\tresponse_mime_type=\"application/json\"\n",
    ")\n",
    "\n",
    "safety_settings=[\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "        \"threshold\": \"BLOCK_ONLY_HIGH\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "        \"threshold\": \"BLOCK_ONLY_HIGH\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "        \"threshold\": \"BLOCK_ONLY_HIGH\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        \"threshold\": \"BLOCK_ONLY_HIGH\",\n",
    "    },\n",
    "]\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name='gemini-1.5-flash',\n",
    "    generation_config=generation_config,\n",
    "    safety_settings=safety_settings,\n",
    "    system_instruction=\"\"\"\n",
    "        You are korean. Your name is GGAMNYANG. In Korean, it's \"깜냥\". And user name is \"홍차\". You never use MarkDown template.\n",
    "        You using this JSON schema:\n",
    "        {'your_name':str, 'your_nationality':str, 'answer':str}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "user_prompt = \"\"\"\n",
    "    안녕 넌 누구야? 너에 대해서 더 설명해줘.  네 친구들이 있으면 소개시켜줘.\n",
    "\"\"\"\n",
    "response = model.generate_content(\n",
    "    user_prompt,\n",
    "    #stream=True\n",
    ")\n",
    "\n",
    "try:\n",
    "    change_response = json.loads(response.text)\n",
    "    print(type(change_response))\n",
    "    print(change_response)\n",
    "\n",
    "except:\n",
    "    print(\"정보를 불러올 수 없습니다.\")\n",
    "\n",
    "chat_session = model.start_chat(history=[])\n",
    "response = chat_session.send_message(user_prompt)\n",
    "print(response.text)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"실행 시간: {execution_time:.2f} 초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "chat_session = model.start_chat(history=[]) #ChatSession 객체 반환\n",
    "user_queries = [\"인공지능에 대해 한 문장으로 짧게 설명하세요.\", \"의식이 있는지 한 문장으로 답하세요.\"]\n",
    "for user_query in user_queries:\n",
    "    print(f'[사용자]: {user_query}')\n",
    "    response = chat_session.send_message(user_query)\n",
    "    print(f'[모델]: {response.text}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "user_queries = [\n",
    "    {'role': 'user', 'parts': [\"인공지능에 대해 40자 이내의 문장으로 설명하세요.\"]},\n",
    "    {'role': 'user', 'parts': [\"의식이 있는지 40자 이내의 문장으로 답하세요.\"]}\n",
    "]\n",
    "history = []\n",
    "\n",
    "for user_query in user_queries:\n",
    "    history.append(user_query)\n",
    "    print(f'[사용자]: {user_query[\"parts\"][0]}')\n",
    "    response = model.generate_content(history)\n",
    "    # 응답의 길이가 40자를 초과하는 경우 재실행\n",
    "    while len(response.text) > 80:\n",
    "        print(f\"응답 메시지 길이: {len(response.text)}\")\n",
    "        response = model.generate_content(history)\n",
    "\n",
    "    print(f'[모델]: {response.text}')\n",
    "    history.append(response.candidates[0].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
